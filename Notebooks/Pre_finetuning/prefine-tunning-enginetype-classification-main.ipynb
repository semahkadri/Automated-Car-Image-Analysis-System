{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-28T21:03:42.967888Z","iopub.execute_input":"2023-04-28T21:03:42.968195Z","iopub.status.idle":"2023-04-28T21:03:43.009951Z","shell.execute_reply.started":"2023-04-28T21:03:42.968166Z","shell.execute_reply":"2023-04-28T21:03:43.008848Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/summary-data-all-columns/Summary_data_all_columns.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup, GPT2ForSequenceClassification, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:03:43.011938Z","iopub.execute_input":"2023-04-28T21:03:43.012686Z","iopub.status.idle":"2023-04-28T21:03:56.079990Z","shell.execute_reply.started":"2023-04-28T21:03:43.012649Z","shell.execute_reply":"2023-04-28T21:03:56.078887Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, TensorDataset\nimport torch\nfrom tqdm.auto import tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup, GPT2ForSequenceClassification, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\nfrom torch.utils.data import DataLoader, TensorDataset\nimport pandas as pd\nimport torch\n\ndf = pd.read_csv('/kaggle/input/summary-data-all-columns/Summary_data_all_columns.csv')\ndf2 = df[['GPT-2 Summarization', 'engine_type', 'drive_type']]\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2', max_length=1024)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:02:55.452484Z","iopub.status.idle":"2023-04-28T21:02:55.452974Z","shell.execute_reply.started":"2023-04-28T21:02:55.452687Z","shell.execute_reply":"2023-04-28T21:02:55.452730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define padding function\ndef pad_sequence(seq, max_len):\n    seq_len = len(seq)\n    if seq_len < max_len:\n        seq = seq + [0] * (max_len - seq_len)\n    elif seq_len > max_len:\n        seq = seq[:max_len]\n    return seq","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:02:55.455832Z","iopub.status.idle":"2023-04-28T21:02:55.456602Z","shell.execute_reply.started":"2023-04-28T21:02:55.456340Z","shell.execute_reply":"2023-04-28T21:02:55.456369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drive_type_labels = {'four wheel drive  ': 0, 'rear wheel drive  ': 1, 'front wheel drive  ': 2, 'all wheel drive  ': 3}\nengine_type_labels = {'Inline 4 ': 0, 'V6 ': 1, 'V8 ': 2, 'Inline 6 ': 3, 'V12 ': 4, 'Inline 5 ': 5, 'Flat 4 ': 6, 'Inline 3 ': 7, 'V10 ': 8}\n\ndf2['drive_type_labels'] = df2['drive_type'].map(drive_type_labels)\ndf2['engine_type_labels'] = df2['engine_type'].map(engine_type_labels)\n\n#tokenized_text = tokenizer(df2['GPT-2 Summarization'].tolist(), truncation=True, padding=True, max_length=1024, return_tensors='pt')\ntokenized_text = df2['GPT-2 Summarization'].apply((lambda x: tokenizer.encode(x, max_length=1024,truncation=True)))","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:02:55.458014Z","iopub.status.idle":"2023-04-28T21:02:55.458823Z","shell.execute_reply.started":"2023-04-28T21:02:55.458519Z","shell.execute_reply":"2023-04-28T21:02:55.458548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lii = df2['engine_type_labels'].tolist()\nlabels = torch.LongTensor(lii)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:02:55.460157Z","iopub.status.idle":"2023-04-28T21:02:55.460931Z","shell.execute_reply.started":"2023-04-28T21:02:55.460641Z","shell.execute_reply":"2023-04-28T21:02:55.460668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_len = 1024\npadded_data = [pad_sequence(seq, max_len) for seq in tokenized_text.values]\n# Convert integers to strings and pad with spaces\npadded_strings = [[' ' + chr(i) for i in seq] for seq in padded_data]\npadded_strings = [[s[1:] for s in seq] for seq in padded_strings]\npadded_strings = [pad_sequence(seq, max_len) for seq in padded_strings]\n# Vectorize padded data\nvectorized_data = np.vectorize(lambda x: ord(x))(padded_strings)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:02:55.462291Z","iopub.status.idle":"2023-04-28T21:02:55.463057Z","shell.execute_reply.started":"2023-04-28T21:02:55.462798Z","shell.execute_reply":"2023-04-28T21:02:55.462826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Flatten padded_data\npadded_data = np.array([np.ravel(x) for x in padded_data]).astype(np.int64)\n# Create attention masks\nattention_masks = np.where(padded_data != 0, 1, 0)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T19:22:40.663160Z","iopub.execute_input":"2023-04-28T19:22:40.665537Z","iopub.status.idle":"2023-04-28T19:22:41.145520Z","shell.execute_reply.started":"2023-04-28T19:22:40.665496Z","shell.execute_reply":"2023-04-28T19:22:41.144343Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model = GPT2ForSequenceClassification.from_pretrained('gpt2', num_labels=9)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T19:22:41.150571Z","iopub.execute_input":"2023-04-28T19:22:41.151569Z","iopub.status.idle":"2023-04-28T19:22:45.565784Z","shell.execute_reply.started":"2023-04-28T19:22:41.151528Z","shell.execute_reply":"2023-04-28T19:22:45.564751Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14182b33b5a54d1caf048e9e087e027f"}},"metadata":{}},{"name":"stderr","text":"Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset = torch.utils.data.TensorDataset(torch.tensor(padded_data), torch.tensor(attention_masks), labels)\n\nbatch_size = 2\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n\noptimizer = AdamW(model.parameters(), lr=1e-5)\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader)*10)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T19:22:45.567505Z","iopub.execute_input":"2023-04-28T19:22:45.567916Z","iopub.status.idle":"2023-04-28T19:22:45.592709Z","shell.execute_reply.started":"2023-04-28T19:22:45.567871Z","shell.execute_reply":"2023-04-28T19:22:45.591594Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel.to(device)\nprint(device)\nmodel.train()","metadata":{"execution":{"iopub.status.busy":"2023-04-28T19:22:45.594395Z","iopub.execute_input":"2023-04-28T19:22:45.595067Z","iopub.status.idle":"2023-04-28T19:22:50.716692Z","shell.execute_reply.started":"2023-04-28T19:22:45.595028Z","shell.execute_reply":"2023-04-28T19:22:50.715613Z"},"scrolled":true,"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"GPT2ForSequenceClassification(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (1): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (2): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (3): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (4): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (5): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (6): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (7): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (8): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (9): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (10): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (11): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (score): Linear(in_features=768, out_features=9, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.pad_token = tokenizer.eos_token\ntokenizer.pad_token_id = tokenizer.eos_token_id\n\n# set padding token id to 0\ntokenizer.pad_token_id = 0\nmodel.config.pad_token_id = model.config.eos_token_id","metadata":{"execution":{"iopub.status.busy":"2023-04-28T19:22:59.453397Z","iopub.execute_input":"2023-04-28T19:22:59.453908Z","iopub.status.idle":"2023-04-28T19:22:59.464785Z","shell.execute_reply.started":"2023-04-28T19:22:59.453858Z","shell.execute_reply":"2023-04-28T19:22:59.463495Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"epochs = 3\n\nfor epoch in tqdm(range(1, epochs+1)):\n    model.train()\n    total_loss = 0\n    for batch in tqdm(train_dataloader):\n        inputs = batch[0].to(device)\n        masks = batch[1].to(device)\n        labels = batch[2].to(device)\n        model.train()\n        optimizer.zero_grad()\n        outputs = model(inputs, attention_mask=masks, labels=labels)\n        loss = outputs[0]\n        total_loss += loss.item()\n        loss.backward()\n        \n        optimizer.step()\n        scheduler.step()\n        acc = torch.mean((torch.argmax(outputs.logits, dim=1) == labels).float())\n        \n    \n    avg_train_loss = total_loss / len(train_dataloader)\n    print(\"Average train loss: {}\".format(avg_train_loss))","metadata":{"execution":{"iopub.status.busy":"2023-04-28T19:23:08.173905Z","iopub.execute_input":"2023-04-28T19:23:08.174277Z","iopub.status.idle":"2023-04-28T19:47:43.865833Z","shell.execute_reply.started":"2023-04-28T19:23:08.174245Z","shell.execute_reply":"2023-04-28T19:47:43.864716Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a1f12bc00d6447391a100fe2736416a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1571 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b8d2e2cd6a749f99601b2412b69ec1f"}},"metadata":{}},{"name":"stdout","text":"Average train loss: 1.3353396226254184\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1571 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05e388b9924c46f7be941effd60a2dca"}},"metadata":{}},{"name":"stdout","text":"Average train loss: 0.7291442123090554\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1571 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3dca5a32abec47f4a59d710ce3b8dd18"}},"metadata":{}},{"name":"stdout","text":"Average train loss: 0.5034420608865503\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save_pretrained('PreFineTune_engine_type')","metadata":{"execution":{"iopub.status.busy":"2023-04-28T19:48:40.544920Z","iopub.execute_input":"2023-04-28T19:48:40.545779Z","iopub.status.idle":"2023-04-28T19:48:41.337396Z","shell.execute_reply.started":"2023-04-28T19:48:40.545738Z","shell.execute_reply":"2023-04-28T19:48:41.336235Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.make_archive(\"PreFineTune_engine_type\", 'zip', \"/kaggle/working/PreFineTune_engine_type\")","metadata":{"execution":{"iopub.status.busy":"2023-04-28T19:48:49.162520Z","iopub.execute_input":"2023-04-28T19:48:49.162939Z","iopub.status.idle":"2023-04-28T19:49:17.600542Z","shell.execute_reply.started":"2023-04-28T19:48:49.162900Z","shell.execute_reply":"2023-04-28T19:49:17.599325Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/PreFineTune_engine_type.zip'"},"metadata":{}}]},{"cell_type":"code","source":"%cd /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2023-04-28T19:49:19.334112Z","iopub.execute_input":"2023-04-28T19:49:19.335064Z","iopub.status.idle":"2023-04-28T19:49:19.342330Z","shell.execute_reply.started":"2023-04-28T19:49:19.334987Z","shell.execute_reply":"2023-04-28T19:49:19.341021Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import FileLink","metadata":{"execution":{"iopub.status.busy":"2023-04-28T19:49:21.489049Z","iopub.execute_input":"2023-04-28T19:49:21.489438Z","iopub.status.idle":"2023-04-28T19:49:21.495331Z","shell.execute_reply.started":"2023-04-28T19:49:21.489402Z","shell.execute_reply":"2023-04-28T19:49:21.493847Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":" FileLink(r'PreFineTune_engine_type.zip')","metadata":{"execution":{"iopub.status.busy":"2023-04-28T19:49:25.365013Z","iopub.execute_input":"2023-04-28T19:49:25.365492Z","iopub.status.idle":"2023-04-28T19:49:25.372491Z","shell.execute_reply.started":"2023-04-28T19:49:25.365446Z","shell.execute_reply":"2023-04-28T19:49:25.371348Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/PreFineTune_engine_type.zip","text/html":"<a href='PreFineTune_engine_type.zip' target='_blank'>PreFineTune_engine_type.zip</a><br>"},"metadata":{}}]}]}