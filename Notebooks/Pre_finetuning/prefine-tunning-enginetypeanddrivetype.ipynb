{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-28T22:09:44.106082Z","iopub.execute_input":"2023-04-28T22:09:44.106773Z","iopub.status.idle":"2023-04-28T22:09:44.128300Z","shell.execute_reply.started":"2023-04-28T22:09:44.106694Z","shell.execute_reply":"2023-04-28T22:09:44.127260Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"/kaggle/input/summary-data-all-columns/Summary_data_all_columns.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup, GPT2ForSequenceClassification, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:09:45.644903Z","iopub.execute_input":"2023-04-28T22:09:45.645514Z","iopub.status.idle":"2023-04-28T22:09:45.651226Z","shell.execute_reply.started":"2023-04-28T22:09:45.645475Z","shell.execute_reply":"2023-04-28T22:09:45.650167Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, TensorDataset\nimport torch\nfrom tqdm.auto import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:09:46.606027Z","iopub.execute_input":"2023-04-28T22:09:46.606442Z","iopub.status.idle":"2023-04-28T22:09:46.611867Z","shell.execute_reply.started":"2023-04-28T22:09:46.606403Z","shell.execute_reply":"2023-04-28T22:09:46.610788Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup, GPT2ForSequenceClassification, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\nfrom torch.utils.data import DataLoader, TensorDataset\nimport pandas as pd\nimport torch\n\ndf = pd.read_csv('/kaggle/input/summary-data-all-columns/Summary_data_all_columns.csv')\ndf2 = df[['GPT-2 Summarization', 'engine_type', 'drive_type']]\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2', max_length=1024)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:09:48.505372Z","iopub.execute_input":"2023-04-28T22:09:48.505756Z","iopub.status.idle":"2023-04-28T22:09:48.941206Z","shell.execute_reply.started":"2023-04-28T22:09:48.505711Z","shell.execute_reply":"2023-04-28T22:09:48.940150Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Define padding function\ndef pad_sequence(seq, max_len):\n    seq_len = len(seq)\n    if seq_len < max_len:\n        seq = seq + [0] * (max_len - seq_len)\n    elif seq_len > max_len:\n        seq = seq[:max_len]\n    return seq","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:09:50.525311Z","iopub.execute_input":"2023-04-28T22:09:50.526277Z","iopub.status.idle":"2023-04-28T22:09:50.532376Z","shell.execute_reply.started":"2023-04-28T22:09:50.526218Z","shell.execute_reply":"2023-04-28T22:09:50.531176Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"drive_type_labels = {'four wheel drive  ': 0, 'rear wheel drive  ': 1, 'front wheel drive  ': 2, 'all wheel drive  ': 3}\nengine_type_labels = {'Inline 4 ': 0, 'V6 ': 1, 'V8 ': 2, 'Inline 6 ': 3, 'V12 ': 4, 'Inline 5 ': 5, 'Flat 4 ': 6, 'Inline 3 ': 7, 'V10 ': 8}\n\ndf2['drive_type_labels'] = df2['drive_type'].map(drive_type_labels)\ndf2['engine_type_labels'] = df2['engine_type'].map(engine_type_labels)\n\n#tokenized_text = tokenizer(df2['GPT-2 Summarization'].tolist(), truncation=True, padding=True, max_length=1024, return_tensors='pt')\ntokenized_text = df2['GPT-2 Summarization'].apply((lambda x: tokenizer.encode(x, max_length=1024,truncation=True)))","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:09:52.725548Z","iopub.execute_input":"2023-04-28T22:09:52.725945Z","iopub.status.idle":"2023-04-28T22:10:02.289422Z","shell.execute_reply.started":"2023-04-28T22:09:52.725912Z","shell.execute_reply":"2023-04-28T22:10:02.288363Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  after removing the cwd from sys.path.\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"\n","output_type":"stream"}]},{"cell_type":"code","source":"lii = df2['drive_type_labels'].tolist()\nlabels = torch.LongTensor(lii)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:10:02.291611Z","iopub.execute_input":"2023-04-28T22:10:02.292474Z","iopub.status.idle":"2023-04-28T22:10:02.298850Z","shell.execute_reply.started":"2023-04-28T22:10:02.292434Z","shell.execute_reply":"2023-04-28T22:10:02.297690Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"max_len = 1024\npadded_data = [pad_sequence(seq, max_len) for seq in tokenized_text.values]\n# Convert integers to strings and pad with spaces\npadded_strings = [[' ' + chr(i) for i in seq] for seq in padded_data]\npadded_strings = [[s[1:] for s in seq] for seq in padded_strings]\npadded_strings = [pad_sequence(seq, max_len) for seq in padded_strings]\n# Vectorize padded data\nvectorized_data = np.vectorize(lambda x: ord(x))(padded_strings)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:10:02.300374Z","iopub.execute_input":"2023-04-28T22:10:02.300847Z","iopub.status.idle":"2023-04-28T22:10:04.954074Z","shell.execute_reply.started":"2023-04-28T22:10:02.300800Z","shell.execute_reply":"2023-04-28T22:10:04.952959Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Flatten padded_data\npadded_data = np.array([np.ravel(x) for x in padded_data]).astype(np.int64)\n# Create attention masks\nattention_masks = np.where(padded_data != 0, 1, 0)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:10:04.957344Z","iopub.execute_input":"2023-04-28T22:10:04.958412Z","iopub.status.idle":"2023-04-28T22:10:05.230366Z","shell.execute_reply.started":"2023-04-28T22:10:04.958370Z","shell.execute_reply":"2023-04-28T22:10:05.229317Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"!conda install -y gdown","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-04-28T21:31:01.409559Z","iopub.execute_input":"2023-04-28T21:31:01.409966Z","iopub.status.idle":"2023-04-28T21:35:06.043561Z","shell.execute_reply.started":"2023-04-28T21:31:01.409927Z","shell.execute_reply":"2023-04-28T21:35:06.042185Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Collecting package metadata (current_repodata.json): done\nSolving environment: | \nThe environment is inconsistent, please check the package plan carefully\nThe following packages are causing the inconsistency:\n\n  - rapidsai/linux-64::libcuml==21.12.00=cuda11_g04c4927f3_0\n  - conda-forge/linux-64::abseil-cpp==20211102.0=h93e1e8c_3\n  - rapidsai/linux-64::dask-cudf==21.12.02=cuda_11_py37_g06540b9b37_0\n  - conda-forge/linux-64::pyarrow==5.0.0=py37h8cf84b7_35_cuda\n  - rapidsai/linux-64::cuml==21.12.00=cuda11_py37_g04c4927f3_0\n  - conda-forge/linux-64::grpc-cpp==1.45.2=he70e3f0_3\n  - rapidsai/linux-64::libcudf==21.12.02=cuda11_g06540b9b37_0\n  - conda-forge/linux-64::arrow-cpp==5.0.0=py37h846d386_35_cuda\n  - rapidsai/linux-64::cudf==21.12.02=cuda_11_py37_g06540b9b37_0\n  - conda-forge/noarch::parquet-cpp==1.5.1=2\n  - conda-forge/linux-64::libabseil==20211102.0=cxx17_h48a1fff_3\ndone\n\n\n==> WARNING: A newer version of conda exists. <==\n  current version: 22.9.0\n  latest version: 23.3.1\n\nPlease update conda by running\n\n    $ conda update -n base -c conda-forge conda\n\n\n\n## Package Plan ##\n\n  environment location: /opt/conda\n\n  added / updated specs:\n    - gdown\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    abseil-cpp-20211102.0      |       h93e1e8c_2          13 KB  conda-forge\n    filelock-3.12.0            |     pyhd8ed1ab_0          14 KB  conda-forge\n    gdown-4.7.1                |     pyhd8ed1ab_0          19 KB  conda-forge\n    libabseil-20211102.0       | cxx17_h48a1fff_2         1.1 MB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         1.1 MB\n\nThe following NEW packages will be INSTALLED:\n\n  filelock           conda-forge/noarch::filelock-3.12.0-pyhd8ed1ab_0 None\n  gdown              conda-forge/noarch::gdown-4.7.1-pyhd8ed1ab_0 None\n\nThe following packages will be DOWNGRADED:\n\n  abseil-cpp                          20211102.0-h93e1e8c_3 --> 20211102.0-h93e1e8c_2 None\n  libabseil                     20211102.0-cxx17_h48a1fff_3 --> 20211102.0-cxx17_h48a1fff_2 None\n\n\n\nDownloading and Extracting Packages\nfilelock-3.12.0      | 14 KB     | ##################################### | 100% \ngdown-4.7.1          | 19 KB     | ##################################### | 100% \nlibabseil-20211102.0 | 1.1 MB    | ##################################### | 100% \nabseil-cpp-20211102. | 13 KB     | ##################################### | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\nRetrieving notices: ...working... done\n","output_type":"stream"}]},{"cell_type":"code","source":"#https://drive.google.com/file/d/16fTX3RS3mF2ayn9YYWoNJBrfg6Cr8kpk/view?usp=share_link","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown --id 16fTX3RS3mF2ayn9YYWoNJBrfg6Cr8kpk #17qBwI-JRxLARe2krOQLVj_87_xvwAEuu","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:35:06.046824Z","iopub.execute_input":"2023-04-28T21:35:06.047530Z","iopub.status.idle":"2023-04-28T21:35:09.981150Z","shell.execute_reply.started":"2023-04-28T21:35:06.047484Z","shell.execute_reply":"2023-04-28T21:35:09.979906Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.7/site-packages/gdown/cli.py:130: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  category=FutureWarning,\nDownloading...\nFrom (uriginal): https://drive.google.com/uc?id=16fTX3RS3mF2ayn9YYWoNJBrfg6Cr8kpk\nFrom (redirected): https://drive.google.com/uc?id=16fTX3RS3mF2ayn9YYWoNJBrfg6Cr8kpk&confirm=t&uuid=dd602b3f-2507-443a-8067-1643b5112f98\nTo: /kaggle/working/PreFineTune_engine_type.zip\n100%|█████████████████████████████████████████| 463M/463M [00:01<00:00, 244MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"! unzip \"/kaggle/working/PreFineTune_engine_type.zip\" -d PreFineTune_engine_type  ","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:36:57.476309Z","iopub.execute_input":"2023-04-28T21:36:57.476736Z","iopub.status.idle":"2023-04-28T21:37:04.181673Z","shell.execute_reply.started":"2023-04-28T21:36:57.476691Z","shell.execute_reply":"2023-04-28T21:37:04.180277Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Archive:  /kaggle/working/PreFineTune_engine_type.zip\n  inflating: PreFineTune_engine_type/pytorch_model.bin  \n  inflating: PreFineTune_engine_type/config.json  \n","output_type":"stream"}]},{"cell_type":"code","source":"model2 = GPT2ForSequenceClassification.from_pretrained('/kaggle/working/PreFineTune_engine_type')","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:10:05.589415Z","iopub.execute_input":"2023-04-28T22:10:05.590051Z","iopub.status.idle":"2023-04-28T22:10:07.348314Z","shell.execute_reply.started":"2023-04-28T22:10:05.590009Z","shell.execute_reply":"2023-04-28T22:10:07.347267Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"model1 = GPT2ForSequenceClassification.from_pretrained('gpt2', num_labels=4)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:10:07.350439Z","iopub.execute_input":"2023-04-28T22:10:07.352015Z","iopub.status.idle":"2023-04-28T22:10:09.335779Z","shell.execute_reply.started":"2023-04-28T22:10:07.351973Z","shell.execute_reply":"2023-04-28T22:10:09.334483Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"model1.base_model.load_state_dict(model2.base_model.state_dict())","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:10:09.341021Z","iopub.execute_input":"2023-04-28T22:10:09.344088Z","iopub.status.idle":"2023-04-28T22:10:09.460990Z","shell.execute_reply.started":"2023-04-28T22:10:09.344040Z","shell.execute_reply":"2023-04-28T22:10:09.459887Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"model1","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-04-28T21:27:59.146235Z","iopub.execute_input":"2023-04-28T21:27:59.147266Z","iopub.status.idle":"2023-04-28T21:27:59.155998Z","shell.execute_reply.started":"2023-04-28T21:27:59.147225Z","shell.execute_reply":"2023-04-28T21:27:59.154882Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"GPT2ForSequenceClassification(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (1): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (2): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (3): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (4): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (5): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (6): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (7): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (8): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (9): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (10): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (11): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (score): Linear(in_features=768, out_features=4, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"#model1.classifier = torch.nn.Linear(768, 4)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model2.score = torch.nn.Linear(768, 4, bias=False)\n#model2.config.num_labels = 4","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:20:10.606298Z","iopub.execute_input":"2023-04-28T21:20:10.606725Z","iopub.status.idle":"2023-04-28T21:20:10.612143Z","shell.execute_reply.started":"2023-04-28T21:20:10.606682Z","shell.execute_reply":"2023-04-28T21:20:10.610928Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_dataset = torch.utils.data.TensorDataset(torch.tensor(padded_data), torch.tensor(attention_masks), labels)\n\nbatch_size = 2\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n\noptimizer = AdamW(model1.parameters(), lr=1e-5)\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader)*10)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:10:12.805227Z","iopub.execute_input":"2023-04-28T22:10:12.805607Z","iopub.status.idle":"2023-04-28T22:10:12.832860Z","shell.execute_reply.started":"2023-04-28T22:10:12.805570Z","shell.execute_reply":"2023-04-28T22:10:12.831883Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel1.to(device)\nprint(device)\nmodel1.train()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-04-28T22:10:15.946840Z","iopub.execute_input":"2023-04-28T22:10:15.947785Z","iopub.status.idle":"2023-04-28T22:10:16.094854Z","shell.execute_reply.started":"2023-04-28T22:10:15.947708Z","shell.execute_reply":"2023-04-28T22:10:16.093786Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"GPT2ForSequenceClassification(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (1): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (2): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (3): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (4): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (5): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (6): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (7): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (8): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (9): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (10): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (11): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (score): Linear(in_features=768, out_features=4, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.pad_token = tokenizer.eos_token\ntokenizer.pad_token_id = tokenizer.eos_token_id\n\n# set padding token id to 0\ntokenizer.pad_token_id = 0\nmodel1.config.pad_token_id = model1.config.eos_token_id","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:10:18.885501Z","iopub.execute_input":"2023-04-28T22:10:18.885904Z","iopub.status.idle":"2023-04-28T22:10:18.891898Z","shell.execute_reply.started":"2023-04-28T22:10:18.885868Z","shell.execute_reply":"2023-04-28T22:10:18.890837Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"epochs = 3\n\nfor epoch in tqdm(range(1, epochs+1)):\n    model1.train()\n    total_loss = 0\n    for batch in tqdm(train_dataloader):\n        inputs = batch[0].to(device)\n        masks = batch[1].to(device)\n        labels = batch[2].to(device)\n        model1.train()\n        optimizer.zero_grad()\n        outputs = model1(inputs, attention_mask=masks, labels=labels)\n        loss = outputs[0]\n        total_loss += loss.item()\n        loss.backward()\n        \n        optimizer.step()\n        scheduler.step()\n        acc = torch.mean((torch.argmax(outputs.logits, dim=1) == labels).float())\n        \n    \n    avg_train_loss = total_loss / len(train_dataloader)\n    print(\"Average train loss: {}\".format(avg_train_loss))","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:10:21.784966Z","iopub.execute_input":"2023-04-28T22:10:21.785369Z","iopub.status.idle":"2023-04-28T22:34:56.663450Z","shell.execute_reply.started":"2023-04-28T22:10:21.785330Z","shell.execute_reply":"2023-04-28T22:34:56.661494Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81b0a476108f4b5b8b492495b29c5cc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1571 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5d6ed7865654a649559737184d2aa39"}},"metadata":{}},{"name":"stdout","text":"Average train loss: 0.5766338995633555\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1571 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49d4aefb7bb74ccfb8f37a9c45f60e9d"}},"metadata":{}},{"name":"stdout","text":"Average train loss: 0.3015456987446856\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1571 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72669d60790c4ed2956267c459ac780f"}},"metadata":{}},{"name":"stdout","text":"Average train loss: 0.22590946091046027\n","output_type":"stream"}]},{"cell_type":"code","source":"model1.save_pretrained('PreFineTune_engine_type_And_Drive_Type')","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:51:26.566441Z","iopub.execute_input":"2023-04-28T22:51:26.567062Z","iopub.status.idle":"2023-04-28T22:51:27.457440Z","shell.execute_reply.started":"2023-04-28T22:51:26.567024Z","shell.execute_reply":"2023-04-28T22:51:27.456205Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.make_archive(\"PreFineTune_engine_type_And_Drive_Type\", 'zip', \"/kaggle/working/PreFineTune_engine_type_And_Drive_Type\")","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:51:38.905388Z","iopub.execute_input":"2023-04-28T22:51:38.905806Z","iopub.status.idle":"2023-04-28T22:52:06.802291Z","shell.execute_reply.started":"2023-04-28T22:51:38.905767Z","shell.execute_reply":"2023-04-28T22:52:06.800228Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/PreFineTune_engine_type_And_Drive_Type.zip'"},"metadata":{}}]},{"cell_type":"code","source":"%cd /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:52:26.785903Z","iopub.execute_input":"2023-04-28T22:52:26.786674Z","iopub.status.idle":"2023-04-28T22:52:26.793455Z","shell.execute_reply.started":"2023-04-28T22:52:26.786631Z","shell.execute_reply":"2023-04-28T22:52:26.792214Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import FileLink","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:52:28.745581Z","iopub.execute_input":"2023-04-28T22:52:28.746195Z","iopub.status.idle":"2023-04-28T22:52:28.751405Z","shell.execute_reply.started":"2023-04-28T22:52:28.746157Z","shell.execute_reply":"2023-04-28T22:52:28.750257Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":" FileLink(r'PreFineTune_engine_type_And_Drive_Type.zip')","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:52:31.050028Z","iopub.execute_input":"2023-04-28T22:52:31.051009Z","iopub.status.idle":"2023-04-28T22:52:31.059068Z","shell.execute_reply.started":"2023-04-28T22:52:31.050952Z","shell.execute_reply":"2023-04-28T22:52:31.057759Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/PreFineTune_engine_type_And_Drive_Type.zip","text/html":"<a href='PreFineTune_engine_type_And_Drive_Type.zip' target='_blank'>PreFineTune_engine_type_And_Drive_Type.zip</a><br>"},"metadata":{}}]}]}