{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-02T20:57:26.471267Z","iopub.execute_input":"2023-05-02T20:57:26.471774Z","iopub.status.idle":"2023-05-02T20:57:26.490731Z","shell.execute_reply.started":"2023-05-02T20:57:26.471735Z","shell.execute_reply":"2023-05-02T20:57:26.489447Z"},"trusted":true,"id":"Q9AAoUAZx10t","outputId":"d733d6e2-48f3-4909-9b69-fb0ae9451bdf"},"execution_count":null,"outputs":[{"name":"stdout","text":"/kaggle/input/questionansweringgpt2-cars/Final_QAS_data_prefinetuning.csv\n","output_type":"stream"}]},{"cell_type":"code","source":["pip install --upgrade transformers\n"],"metadata":{"execution":{"iopub.status.busy":"2023-05-02T20:56:46.180533Z","iopub.execute_input":"2023-05-02T20:56:46.180796Z","iopub.status.idle":"2023-05-02T20:57:09.205186Z","shell.execute_reply.started":"2023-05-02T20:56:46.180769Z","shell.execute_reply":"2023-05-02T20:57:09.203566Z"},"trusted":true,"id":"1S5kA68Wx103","outputId":"191912ef-8b40-45e9-ce1a-dd4156673ea2"},"execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.27.4)\nCollecting transformers\n  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.9.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.11.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.14)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\nInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.27.4\n    Uninstalling transformers-4.27.4:\n      Successfully uninstalled transformers-4.27.4\nSuccessfully installed transformers-4.28.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":["import torch\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup"],"metadata":{"execution":{"iopub.status.busy":"2023-05-02T20:57:33.284951Z","iopub.execute_input":"2023-05-02T20:57:33.285324Z","iopub.status.idle":"2023-05-02T20:57:33.290547Z","shell.execute_reply.started":"2023-05-02T20:57:33.285291Z","shell.execute_reply":"2023-05-02T20:57:33.289412Z"},"trusted":true,"id":"gwbkBndTx104"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the CSV dataset\n","df = pd.read_csv('/kaggle/input/questionansweringgpt2-cars/Final_QAS_data_prefinetuning.csv')\n"],"metadata":{"execution":{"iopub.status.busy":"2023-05-02T20:57:36.871447Z","iopub.execute_input":"2023-05-02T20:57:36.872066Z","iopub.status.idle":"2023-05-02T20:57:37.493484Z","shell.execute_reply.started":"2023-05-02T20:57:36.872025Z","shell.execute_reply":"2023-05-02T20:57:37.492115Z"},"trusted":true,"id":"RyNQxQKcx105"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['context'].str.split().str.len().hist()"],"metadata":{"execution":{"iopub.status.busy":"2023-05-02T20:57:38.738222Z","iopub.execute_input":"2023-05-02T20:57:38.738722Z","iopub.status.idle":"2023-05-02T20:57:39.662716Z","shell.execute_reply.started":"2023-05-02T20:57:38.738680Z","shell.execute_reply":"2023-05-02T20:57:39.661650Z"},"trusted":true,"id":"5Srpdl3Rx107","outputId":"fb5fe1c2-8772-41e3-bb54-80b920ab0206"},"execution_count":null,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["df.head()"],"metadata":{"execution":{"iopub.status.busy":"2023-05-02T20:57:41.734507Z","iopub.execute_input":"2023-05-02T20:57:41.735043Z","iopub.status.idle":"2023-05-02T20:57:41.762370Z","shell.execute_reply.started":"2023-05-02T20:57:41.735006Z","shell.execute_reply":"2023-05-02T20:57:41.761178Z"},"trusted":true,"id":"WknJLf8Hx108","outputId":"b7fd5ea4-05c6-457e-807e-ca5ef4b79eb0"},"execution_count":null,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                            question answer  start_pos  \\\n0  What is the horsepower rating of the engine in...    120         73   \n1  What is the horsepower output of the toyota 4r...    245         68   \n2  What is the horsepower rating of the engine in...    190         67   \n3  What is the horsepower output of the toyota ta...    142         73   \n4  How many horsepower does the ford ranger 1990'...    100         71   \n\n   end_pos                                            context  \n0       86  The jeep wrangler 1998 is a vehicle with a Inl...  \n1       81  The toyota 4runner 2005 is a vehicle with a V6...  \n2       80  The toyota tundra 2002 is a vehicle with a V6 ...  \n3       86  The toyota tacoma 1998 is a vehicle with a Inl...  \n4       84  The ford ranger 1990 is a vehicle with a Inlin...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n      <th>start_pos</th>\n      <th>end_pos</th>\n      <th>context</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What is the horsepower rating of the engine in...</td>\n      <td>120</td>\n      <td>73</td>\n      <td>86</td>\n      <td>The jeep wrangler 1998 is a vehicle with a Inl...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What is the horsepower output of the toyota 4r...</td>\n      <td>245</td>\n      <td>68</td>\n      <td>81</td>\n      <td>The toyota 4runner 2005 is a vehicle with a V6...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>What is the horsepower rating of the engine in...</td>\n      <td>190</td>\n      <td>67</td>\n      <td>80</td>\n      <td>The toyota tundra 2002 is a vehicle with a V6 ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What is the horsepower output of the toyota ta...</td>\n      <td>142</td>\n      <td>73</td>\n      <td>86</td>\n      <td>The toyota tacoma 1998 is a vehicle with a Inl...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>How many horsepower does the ford ranger 1990'...</td>\n      <td>100</td>\n      <td>71</td>\n      <td>84</td>\n      <td>The ford ranger 1990 is a vehicle with a Inlin...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":["qa_pairs = []\n","for index, q in df.iterrows():\n","    qa_pairs.append(q['context'] + ' ' + q['question'] + ' [SEP] ' + q['answer'])"],"metadata":{"execution":{"iopub.status.busy":"2023-05-02T20:57:43.997159Z","iopub.execute_input":"2023-05-02T20:57:43.997514Z","iopub.status.idle":"2023-05-02T20:57:44.527381Z","shell.execute_reply.started":"2023-05-02T20:57:43.997484Z","shell.execute_reply":"2023-05-02T20:57:44.526312Z"},"trusted":true,"id":"-iAneNMAx109"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!conda install -y gdown"],"metadata":{"execution":{"iopub.status.busy":"2023-05-02T20:58:06.644565Z","iopub.execute_input":"2023-05-02T20:58:06.645079Z","iopub.status.idle":"2023-05-02T21:02:14.826024Z","shell.execute_reply.started":"2023-05-02T20:58:06.645033Z","shell.execute_reply":"2023-05-02T21:02:14.824635Z"},"scrolled":true,"trusted":true,"id":"5XMllZpex10-","outputId":"e2ef972a-d200-4e78-c007-ecc15a335c7d"},"execution_count":null,"outputs":[{"name":"stdout","text":"Collecting package metadata (current_repodata.json): done\nSolving environment: - \nThe environment is inconsistent, please check the package plan carefully\nThe following packages are causing the inconsistency:\n\n  - rapidsai/linux-64::libcuml==21.12.00=cuda11_g04c4927f3_0\n  - conda-forge/linux-64::abseil-cpp==20211102.0=h93e1e8c_3\n  - rapidsai/linux-64::dask-cudf==21.12.02=cuda_11_py37_g06540b9b37_0\n  - conda-forge/linux-64::pyarrow==5.0.0=py37h8cf84b7_35_cuda\n  - rapidsai/linux-64::cuml==21.12.00=cuda11_py37_g04c4927f3_0\n  - conda-forge/linux-64::grpc-cpp==1.45.2=he70e3f0_3\n  - rapidsai/linux-64::libcudf==21.12.02=cuda11_g06540b9b37_0\n  - conda-forge/linux-64::arrow-cpp==5.0.0=py37h846d386_35_cuda\n  - rapidsai/linux-64::cudf==21.12.02=cuda_11_py37_g06540b9b37_0\n  - conda-forge/noarch::parquet-cpp==1.5.1=2\n  - conda-forge/linux-64::libabseil==20211102.0=cxx17_h48a1fff_3\ndone\n\n\n==> WARNING: A newer version of conda exists. <==\n  current version: 22.9.0\n  latest version: 23.3.1\n\nPlease update conda by running\n\n    $ conda update -n base -c conda-forge conda\n\n\n\n## Package Plan ##\n\n  environment location: /opt/conda\n\n  added / updated specs:\n    - gdown\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    abseil-cpp-20211102.0      |       h93e1e8c_2          13 KB  conda-forge\n    filelock-3.12.0            |     pyhd8ed1ab_0          14 KB  conda-forge\n    gdown-4.7.1                |     pyhd8ed1ab_0          19 KB  conda-forge\n    libabseil-20211102.0       | cxx17_h48a1fff_2         1.1 MB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         1.1 MB\n\nThe following NEW packages will be INSTALLED:\n\n  filelock           conda-forge/noarch::filelock-3.12.0-pyhd8ed1ab_0 None\n  gdown              conda-forge/noarch::gdown-4.7.1-pyhd8ed1ab_0 None\n\nThe following packages will be DOWNGRADED:\n\n  abseil-cpp                          20211102.0-h93e1e8c_3 --> 20211102.0-h93e1e8c_2 None\n  libabseil                     20211102.0-cxx17_h48a1fff_3 --> 20211102.0-cxx17_h48a1fff_2 None\n\n\n\nDownloading and Extracting Packages\ngdown-4.7.1          | 19 KB     | ##################################### | 100% \nfilelock-3.12.0      | 14 KB     | ##################################### | 100% \nlibabseil-20211102.0 | 1.1 MB    | ##################################### | 100% \nabseil-cpp-20211102. | 13 KB     | ##################################### | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\nRetrieving notices: ...working... done\n","output_type":"stream"}]},{"cell_type":"code","source":["# https://drive.google.com/file/d//view?usp=share_link"],"metadata":{"id":"aYNl8o23x10_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!gdown --id 1ivZc4FbVM4eNmP6q6MwkD7m4w_pkHRzX #17qBwI-JRxLARe2krOQLVj_87_xvwAEuu"],"metadata":{"execution":{"iopub.status.busy":"2023-05-02T21:03:02.249843Z","iopub.execute_input":"2023-05-02T21:03:02.250655Z","iopub.status.idle":"2023-05-02T21:03:12.577596Z","shell.execute_reply.started":"2023-05-02T21:03:02.250612Z","shell.execute_reply":"2023-05-02T21:03:12.576159Z"},"trusted":true,"id":"gcML-Dl1x11A","outputId":"cb906d7e-87ab-4339-8641-fb33b70fd77e"},"execution_count":null,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.7/site-packages/gdown/cli.py:130: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  category=FutureWarning,\nDownloading...\nFrom (uriginal): https://drive.google.com/uc?id=1ivZc4FbVM4eNmP6q6MwkD7m4w_pkHRzX\nFrom (redirected): https://drive.google.com/uc?id=1ivZc4FbVM4eNmP6q6MwkD7m4w_pkHRzX&confirm=t&uuid=f93baa38-6d2c-4d55-aa45-33279e8044ec\nTo: /kaggle/working/PreFineTune_engine_type_And_Drive_Type.zip\n100%|████████████████████████████████████████| 463M/463M [00:08<00:00, 56.9MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":["! unzip \"/kaggle/working/PreFineTune_engine_type_And_Drive_Type.zip\" -d PreFineTune_engine_type_And_Drive_Type  "],"metadata":{"execution":{"iopub.status.busy":"2023-05-02T21:03:26.177517Z","iopub.execute_input":"2023-05-02T21:03:26.178742Z","iopub.status.idle":"2023-05-02T21:03:32.272851Z","shell.execute_reply.started":"2023-05-02T21:03:26.178693Z","shell.execute_reply":"2023-05-02T21:03:32.271325Z"},"trusted":true,"id":"PTCLkD3Ax11B","outputId":"fe7ea018-c560-4b92-bb28-c6a16e2941b0"},"execution_count":null,"outputs":[{"name":"stdout","text":"Archive:  /kaggle/working/PreFineTune_engine_type_And_Drive_Type.zip\n  inflating: PreFineTune_engine_type_And_Drive_Type/config.json  \n  inflating: PreFineTune_engine_type_And_Drive_Type/pytorch_model.bin  \n","output_type":"stream"}]},{"cell_type":"code","source":["tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","model = GPT2LMHeadModel.from_pretrained('/kaggle/working/PreFineTune_engine_type_And_Drive_Type')"],"metadata":{"execution":{"iopub.status.busy":"2023-05-02T21:03:34.036940Z","iopub.execute_input":"2023-05-02T21:03:34.037764Z","iopub.status.idle":"2023-05-02T21:03:38.185119Z","shell.execute_reply.started":"2023-05-02T21:03:34.037719Z","shell.execute_reply":"2023-05-02T21:03:38.184174Z"},"trusted":true,"id":"BL27elzrx11C","outputId":"5b018d3a-0ee0-4512-e1f8-06cfcfcf3fc4","colab":{"referenced_widgets":["864a1e0112454861aa8ab468d3eab993","2ada770ca5f540248ede4b52a72dac9b","9727e1bd1a60456a911162c03bd46edd"]}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"864a1e0112454861aa8ab468d3eab993"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ada770ca5f540248ede4b52a72dac9b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9727e1bd1a60456a911162c03bd46edd"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at /kaggle/working/PreFineTune_engine_type_And_Drive_Type were not used when initializing GPT2LMHeadModel: ['score.weight']\n- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":["tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","model = GPT2LMHeadModel.from_pretrained('gpt2')"],"metadata":{"execution":{"iopub.status.busy":"2023-05-01T16:46:17.873891Z","iopub.execute_input":"2023-05-01T16:46:17.875098Z","iopub.status.idle":"2023-05-01T16:46:21.935350Z","shell.execute_reply.started":"2023-05-01T16:46:17.875037Z","shell.execute_reply":"2023-05-01T16:46:21.934299Z"},"trusted":true,"id":"GBFnXPzHx11D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hMILEZSgx11D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.pad_token = tokenizer.eos_token"],"metadata":{"execution":{"iopub.status.busy":"2023-05-02T21:03:45.479808Z","iopub.execute_input":"2023-05-02T21:03:45.481172Z","iopub.status.idle":"2023-05-02T21:03:45.487190Z","shell.execute_reply.started":"2023-05-02T21:03:45.481079Z","shell.execute_reply":"2023-05-02T21:03:45.485548Z"},"trusted":true,"id":"QFqi2FV4x11E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoded = tokenizer(qa_pairs, padding=True, truncation=True, return_tensors='pt')"],"metadata":{"execution":{"iopub.status.busy":"2023-05-02T21:03:47.877865Z","iopub.execute_input":"2023-05-02T21:03:47.878285Z","iopub.status.idle":"2023-05-02T21:04:24.223769Z","shell.execute_reply.started":"2023-05-02T21:03:47.878250Z","shell.execute_reply":"2023-05-02T21:04:24.222529Z"},"trusted":true,"id":"ydDTjmOSx11E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids = encoded['input_ids']\n","attention_mask = encoded['attention_mask']\n","labels = input_ids.clone()"],"metadata":{"execution":{"iopub.status.busy":"2023-05-02T21:04:24.226443Z","iopub.execute_input":"2023-05-02T21:04:24.226880Z","iopub.status.idle":"2023-05-02T21:04:24.245529Z","shell.execute_reply.started":"2023-05-02T21:04:24.226838Z","shell.execute_reply":"2023-05-02T21:04:24.244306Z"},"trusted":true,"id":"rtqnutnXx11F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i, qa in df.iterrows():\n","    answer = qa['answer']\n","    answer_start = qa['start_pos']\n","    answer_end = answer_start + len(answer)\n","    labels[i, answer_start:answer_end] = input_ids[i, answer_start:answer_end]\n"],"metadata":{"execution":{"iopub.status.busy":"2023-05-02T21:04:24.247349Z","iopub.execute_input":"2023-05-02T21:04:24.247715Z","iopub.status.idle":"2023-05-02T21:04:24.927246Z","shell.execute_reply.started":"2023-05-02T21:04:24.247678Z","shell.execute_reply":"2023-05-02T21:04:24.926203Z"},"trusted":true,"id":"iLoGBpiyx11F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer = AdamW(model.parameters(), lr=1e-5)\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=1000)\n","model.train()"],"metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-05-02T21:04:24.929439Z","iopub.execute_input":"2023-05-02T21:04:24.929881Z","iopub.status.idle":"2023-05-02T21:04:24.959349Z","shell.execute_reply.started":"2023-05-02T21:04:24.929843Z","shell.execute_reply":"2023-05-02T21:04:24.958201Z"},"trusted":true,"id":"ClhQnwfXx11G","outputId":"bfae378a-0c3b-4908-db3a-369ba4744365"},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (1): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (2): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (3): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (4): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (5): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (6): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (7): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (8): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (9): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (10): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (11): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":["# Split the dataset into training and validation sets\n","from sklearn.model_selection import train_test_split\n","train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state=42, test_size=0.2)\n","\n","# Split the masks into training and validation sets\n","train_masks, validation_masks, _, _ = train_test_split(attention_mask, input_ids, random_state=42, test_size=0.2)\n","\n","# Convert all of our data into torch tensors, the required datatype for our model\n","train_inputs = torch.tensor(train_inputs)\n","validation_inputs = torch.tensor(validation_inputs)\n","train_labels = torch.tensor(train_labels)\n","validation_labels = torch.tensor(validation_labels)\n","train_masks = torch.tensor(train_masks)\n","validation_masks = torch.tensor(validation_masks)\n"],"metadata":{"execution":{"iopub.status.busy":"2023-05-02T21:04:34.303105Z","iopub.execute_input":"2023-05-02T21:04:34.303487Z","iopub.status.idle":"2023-05-02T21:04:35.099543Z","shell.execute_reply.started":"2023-05-02T21:04:34.303454Z","shell.execute_reply":"2023-05-02T21:04:35.098358Z"},"trusted":true,"id":"JJ68CTeIx11H","outputId":"1806f715-5012-45a6-8d52-1449fdb95a65"},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  if __name__ == \"__main__\":\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  # Remove the CWD from sys.path while we load stuff.\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  # This is added back by InteractiveShellApp.init_path()\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  if sys.path[0] == \"\":\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  del sys.path[0]\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \n","output_type":"stream"}]},{"cell_type":"code","source":["from tqdm.auto import tqdm"],"metadata":{"execution":{"iopub.status.busy":"2023-05-02T21:06:19.180659Z","iopub.execute_input":"2023-05-02T21:06:19.181608Z","iopub.status.idle":"2023-05-02T21:06:19.187675Z","shell.execute_reply.started":"2023-05-02T21:06:19.181551Z","shell.execute_reply":"2023-05-02T21:06:19.186060Z"},"trusted":true,"id":"0aFfHjwRx11H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 2\n","\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"],"metadata":{"execution":{"iopub.status.busy":"2023-05-02T21:04:44.182969Z","iopub.execute_input":"2023-05-02T21:04:44.183344Z","iopub.status.idle":"2023-05-02T21:04:44.190535Z","shell.execute_reply.started":"2023-05-02T21:04:44.183312Z","shell.execute_reply":"2023-05-02T21:04:44.189202Z"},"trusted":true,"id":"flouzhyNx11I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the AdamW optimizer\n","optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n","\n","# Total number of training steps is number of batches * number of epochs.\n","total_steps = len(train_dataloader) * 3\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=2).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"execution":{"iopub.status.busy":"2023-05-02T21:05:27.508535Z","iopub.execute_input":"2023-05-02T21:05:27.508903Z","iopub.status.idle":"2023-05-02T21:05:27.522027Z","shell.execute_reply.started":"2023-05-02T21:05:27.508869Z","shell.execute_reply":"2023-05-02T21:05:27.519649Z"},"trusted":true,"id":"Nlhe66Nex11I","outputId":"f203ccf7-0e0c-493a-afa4-dbddeaae1a27"},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n","output_type":"stream"}]},{"cell_type":"code","source":["# Store the average loss after each epoch so we can plot them.\n","loss_values = []\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","print(device)\n","# For each epoch...\n","for epoch_i in tqdm(range(0, 3)):\n","    \n","        # ========================================\n","        #               Training\n","        # ========================================\n","    \n","        # Perform one full pass over the training set.\n","    \n","        # Put the model into training mode. Don't be mislead--the call to `train` just changes the *mode*, it doesn't *perform* the training.\n","        # `dropout` and `batchnorm` layers behave differently during training vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","        model.train()\n","    \n","        # Tracking variables\n","        tr_loss = 0\n","        nb_tr_examples, nb_tr_steps = 0, 0\n","    \n","        # Train the data for one epoch\n","        for step, batch in enumerate(tqdm(train_dataloader)):\n","            # Add batch to GPU\n","            batch = tuple(t.to(device) for t in batch)\n","            # Unpack the inputs from our dataloader\n","            b_input_ids, b_input_mask, b_labels = batch\n","            # Clear out the gradients (by default they accumulate)\n","            optimizer.zero_grad()\n","            # Forward pass\n","            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","            loss = outputs[0]\n","            logits = outputs[1]\n","            # Backward pass\n","            loss.backward()\n","            # Update parameters and take a step using the computed gradient\n","            optimizer.step()\n","            # Update the learning rate.\n","            scheduler.step()\n","    \n","            # Update tracking variables\n","            tr_loss += loss.item()\n","            nb_tr_examples += b_input_ids.size(0)\n","            nb_tr_steps += 1\n","            if step % 200 == 0:\n","                print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n","    \n","        print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n","    \n","        # ========================================\n","        #               Validation\n","        # ========================================\n","        # After the completion of each training epoch, measure our performance on\n","        # our validation set.\n","    \n","        # Put the model into evaluation mode--the dropout layers behave differently\n","        # during evaluation.\n","        model.eval()\n","    \n","        # Tracking variables\n","        eval_loss, eval_accuracy = 0, 0\n","        nb_eval_steps, nb_eval_examples = 0, 0\n","    \n","        # Evaluate data for one epoch\n","        for batch in validation_dataloader:\n","            # Add batch to GPU\n","            batch = tuple(t.to(device) for t in batch)\n","            # Unpack the inputs from our dataloader\n","            b_input_ids, b_input_mask, b_labels = batch"],"metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-05-02T21:06:22.892118Z","iopub.execute_input":"2023-05-02T21:06:22.892510Z","iopub.status.idle":"2023-05-02T23:20:10.433659Z","shell.execute_reply.started":"2023-05-02T21:06:22.892479Z","shell.execute_reply":"2023-05-02T23:20:10.432291Z"},"trusted":true,"id":"ZJrjc2uhx11J","outputId":"c6e83a65-4c4f-4b0a-f90a-4510706e99b0","colab":{"referenced_widgets":["b9a0500732aa47ad9cde3797276dfd37","9801aba819f342b89eac9c8d4a52fe0a","1740550e8d3c42e7ad7937eb59e0f5ef","715cf2517b1240aebc2110c33dace963"]}},"execution_count":null,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9a0500732aa47ad9cde3797276dfd37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3769 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9801aba819f342b89eac9c8d4a52fe0a"}},"metadata":{}},{"name":"stdout","text":"Train loss: 10.680669784545898\nTrain loss: 1.6136097758267056\nTrain loss: 1.433538445139169\nTrain loss: 1.3583810826307923\nTrain loss: 1.314329263646058\nTrain loss: 1.2734218952018064\nTrain loss: 1.2490824466504522\nTrain loss: 1.2268767876392344\nTrain loss: 1.2078102748191855\nTrain loss: 1.1938053362447973\nTrain loss: 1.1778986785581325\nTrain loss: 1.1661531726733656\nTrain loss: 1.1546525313972384\nTrain loss: 1.1439366188360058\nTrain loss: 1.1340450882188169\nTrain loss: 1.1235310343186962\nTrain loss: 1.1142081480283583\nTrain loss: 1.1056207128611777\nTrain loss: 1.0988460589128877\nTrain loss: 1.0923004470672681\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3769 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1740550e8d3c42e7ad7937eb59e0f5ef"}},"metadata":{}},{"name":"stdout","text":"Train loss: 1.3521559238433838\nTrain loss: 0.9138702323187643\nTrain loss: 0.9265371278634392\nTrain loss: 0.9290278836117807\nTrain loss: 0.9217352269963826\nTrain loss: 0.9177255950696938\nTrain loss: 0.9160215076583311\nTrain loss: 0.9110595791425814\nTrain loss: 0.901764220663397\nTrain loss: 0.8967423280726897\nTrain loss: 0.8962230046392827\nTrain loss: 0.8947280893954485\nTrain loss: 0.8925843236332558\nTrain loss: 0.8921142945833066\nTrain loss: 0.8910363069251686\nTrain loss: 0.8890841136792329\nTrain loss: 0.8856325239927666\nTrain loss: 0.8853587100216043\nTrain loss: 0.8829817190110452\nTrain loss: 0.8817958849192883\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3769 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"715cf2517b1240aebc2110c33dace963"}},"metadata":{}},{"name":"stdout","text":"Train loss: 1.0573992729187012\nTrain loss: 0.8351135414408807\nTrain loss: 0.8113905857142962\nTrain loss: 0.825494384520165\nTrain loss: 0.8191689646031972\nTrain loss: 0.8223079142945035\nTrain loss: 0.8174004310697044\nTrain loss: 0.8142454422834854\nTrain loss: 0.8160811182481471\nTrain loss: 0.8140119209591876\nTrain loss: 0.8109106720517809\nTrain loss: 0.8114210278157996\nTrain loss: 0.8105710986450855\nTrain loss: 0.8081787770677763\nTrain loss: 0.8070483951696708\nTrain loss: 0.8064573949295376\nTrain loss: 0.8044793519753846\nTrain loss: 0.8031117489161088\nTrain loss: 0.8022033158535594\nTrain loss: 0.8024635913854222\n","output_type":"stream"}]},{"cell_type":"code","source":["model.save_pretrained('PreFineTune_question_answering_engine_type_And_Drive_Type')"],"metadata":{"execution":{"iopub.status.busy":"2023-05-02T23:20:27.414186Z","iopub.execute_input":"2023-05-02T23:20:27.414947Z","iopub.status.idle":"2023-05-02T23:20:28.187729Z","shell.execute_reply.started":"2023-05-02T23:20:27.414897Z","shell.execute_reply":"2023-05-02T23:20:28.186681Z"},"trusted":true,"id":"3zcppyN3x11L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import shutil\n","shutil.make_archive(\"PreFineTune_question_answering_engine_type_And_Drive_Type\", 'zip', \"/kaggle/working/PreFineTune_question_answering_engine_type_And_Drive_Type\")"],"metadata":{"execution":{"iopub.status.busy":"2023-05-02T23:21:02.585869Z","iopub.execute_input":"2023-05-02T23:21:02.586602Z","iopub.status.idle":"2023-05-02T23:21:30.542506Z","shell.execute_reply.started":"2023-05-02T23:21:02.586542Z","shell.execute_reply":"2023-05-02T23:21:30.541320Z"},"trusted":true,"id":"7FYfiGIqx11M","outputId":"3cfff654-c3b3-4c91-89eb-7ded82fea5af"},"execution_count":null,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/PreFineTune_question_answering_engine_type_And_Drive_Type.zip'"},"metadata":{}}]},{"cell_type":"code","source":["from IPython.display import FileLink\n","FileLink(r'/kaggle/working/PreFineTune_question_answering_engine_type_And_Drive_Type.zip')"],"metadata":{"execution":{"iopub.status.busy":"2023-05-02T23:21:35.969330Z","iopub.execute_input":"2023-05-02T23:21:35.970056Z","iopub.status.idle":"2023-05-02T23:21:35.976829Z","shell.execute_reply.started":"2023-05-02T23:21:35.970015Z","shell.execute_reply":"2023-05-02T23:21:35.975794Z"},"trusted":true,"id":"0JmmjeZcx11N","outputId":"a6700e3a-2482-4c0b-b386-4907aaa5d541"},"execution_count":null,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/PreFineTune_question_answering_engine_type_And_Drive_Type.zip","text/html":"<a href='/kaggle/working/PreFineTune_question_answering_engine_type_And_Drive_Type.zip' target='_blank'>/kaggle/working/PreFineTune_question_answering_engine_type_And_Drive_Type.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":["%cd /kaggle/working"],"metadata":{"execution":{"iopub.status.busy":"2023-05-02T23:21:43.314215Z","iopub.execute_input":"2023-05-02T23:21:43.314574Z","iopub.status.idle":"2023-05-02T23:21:43.323442Z","shell.execute_reply.started":"2023-05-02T23:21:43.314542Z","shell.execute_reply":"2023-05-02T23:21:43.322101Z"},"trusted":true,"id":"xD-ZIlC-x11N","outputId":"46b19ed8-4889-4a04-e695-767e6409da42"},"execution_count":null,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":[" FileLink(r'PreFineTune_question_answering_engine_type_And_Drive_Type.zip')"],"metadata":{"execution":{"iopub.status.busy":"2023-05-02T23:21:45.133725Z","iopub.execute_input":"2023-05-02T23:21:45.134634Z","iopub.status.idle":"2023-05-02T23:21:45.142537Z","shell.execute_reply.started":"2023-05-02T23:21:45.134581Z","shell.execute_reply":"2023-05-02T23:21:45.141429Z"},"trusted":true,"id":"_vNtyIEOx11P","outputId":"2e37571b-a6c2-4251-890f-e6ca1a67d868"},"execution_count":null,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/PreFineTune_question_answering_engine_type_And_Drive_Type.zip","text/html":"<a href='PreFineTune_question_answering_engine_type_And_Drive_Type.zip' target='_blank'>PreFineTune_question_answering_engine_type_And_Drive_Type.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(50257, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False))\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)))\n","      ...\n","      (6): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False))\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )))\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True))\n","  (lm_head): Linear(in_features=768, out_features=50257, bias=False))"],"metadata":{"id":"7bxAsryoqfIH"},"execution_count":null,"outputs":[]}]}